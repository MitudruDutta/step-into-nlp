{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93564c40",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning with Hugging Face ðŸŽ¯\n",
    "\n",
    "Fine-tuning adapts a pretrained model to your specific task by continuing training on task-specific data. This notebook demonstrates fine-tuning BERT on the **GLUE MRPC** (Microsoft Research Paraphrase Corpus) dataset for paraphrase detection.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Loading datasets from Hugging Face Hub\n",
    "- Tokenizing data for transformer models\n",
    "- Using DataCollator for efficient batching\n",
    "- Configuring training with TrainingArguments\n",
    "- Training with the Trainer API\n",
    "- Evaluating and making predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fc98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 19:41:14.166394: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 19:41:14.359869: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-02 19:41:16.268132: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 19:41:16.268416: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/btwitsvoid/python/lib64/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27181f17",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "We need `transformers` for models/tokenizers, `datasets` for data loading, and `sklearn` for evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491de00",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c272878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b650f6e09847008bc444b14879045d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db2ada552594795abe79c141dd1adf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb6645295644c9b3a7166735a780c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739e7c3948fc46aba4105f4e6005ffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0a6d333af24a79920f41f41edfbc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854f87d0d252407c8273254183d03670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ff94a93a0f4719a9c119a15a3dcfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2416425",
   "metadata": {},
   "source": [
    "**GLUE MRPC Dataset**: Given two sentences, predict if they are paraphrases (semantically equivalent).\n",
    "- **Label 1**: Paraphrase (same meaning)\n",
    "- **Label 0**: Not a paraphrase (different meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5dc91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418881ce",
   "metadata": {},
   "source": [
    "Let's examine a single training example to understand the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\", 'sentence2': \"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\", 'label': 0, 'idx': 1}\n",
      "{'sentence1': 'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .', 'sentence2': 'Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .', 'label': 0, 'idx': 3}\n",
      "{'sentence1': 'The Nasdaq had a weekly gain of 17.27 , or 1.2 percent , closing at 1,520.15 on Friday .', 'sentence2': 'The tech-laced Nasdaq Composite .IXIC rallied 30.46 points , or 2.04 percent , to 1,520.15 .', 'label': 0, 'idx': 6}\n",
      "{'sentence1': 'That compared with $ 35.18 million , or 24 cents per share , in the year-ago period .', 'sentence2': 'Earnings were affected by a non-recurring $ 8 million tax benefit in the year-ago period .', 'label': 0, 'idx': 8}\n",
      "{'sentence1': 'Shares of Genentech , a much larger company with several products on the market , rose more than 2 percent .', 'sentence2': 'Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger company with several products on the market , were up 2 percent .', 'label': 0, 'idx': 10}\n",
      "{'sentence1': 'Legislation making it harder for consumers to erase their debts in bankruptcy court won overwhelming House approval in March .', 'sentence2': 'Legislation making it harder for consumers to erase their debts in bankruptcy court won speedy , House approval in March and was endorsed by the White House .', 'label': 0, 'idx': 11}\n",
      "{'sentence1': 'The Nasdaq composite index increased 10.73 , or 0.7 percent , to 1,514.77 .', 'sentence2': 'The Nasdaq Composite index , full of technology stocks , was lately up around 18 points .', 'label': 0, 'idx': 12}\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "count = 0\n",
    "for record in dataset['train']:\n",
    "    if record['label']==0:\n",
    "        print(record)\n",
    "        if count >= threshold:\n",
    "            break\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063b163",
   "metadata": {},
   "source": [
    "Let's look at some negative examples (non-paraphrases) to understand when sentences have different meanings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ef7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value('string'),\n",
       " 'sentence2': Value('string'),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent']),\n",
       " 'idx': Value('int32')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64fbdd",
   "metadata": {},
   "source": [
    "Check the dataset features (column types and label mappings):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1066ac6",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba391a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91bb9f81a4d4dd2b2eb37eb4709a3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609b139c08164e3eada9a24a636ed880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e2057571884129a31cdda1897a0ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c5329",
   "metadata": {},
   "source": [
    "We tokenize **both sentences together** so the model can learn their relationship. The tokenizer:\n",
    "- Adds [CLS] at the start\n",
    "- Separates sentences with [SEP]\n",
    "- Creates attention masks\n",
    "\n",
    "Using `batched=True` processes multiple examples at once for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f4cbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a0e1e",
   "metadata": {},
   "source": [
    "Notice the dataset now has additional columns: `input_ids`, `attention_mask`, and `token_type_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f12d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for PyTorch\n",
    "train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42)\n",
    "valid_dataset = tokenized_dataset[\"validation\"]\n",
    "test_dataset = tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f55c49",
   "metadata": {},
   "source": [
    "### Prepare Train/Validation/Test Splits\n",
    "\n",
    "Shuffle training data for better generalization. Keep validation and test sets in original order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f5a777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data collator is used for dynamic padding per batch. For example batch 1 has texts of \n",
    "# size 10, 12 and 15. batch 2 has sizes 8, 6 and 9. Due to collator batch 1 will be padded to\n",
    "# max size of 15 whereas batch 2 will be padded to a max size of 9. The other option is to apply\n",
    "# global padding that will tax max length from the entire dataset and pad all other text to that max\n",
    "# length which is not efficient\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0b7503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95b4ca",
   "metadata": {},
   "source": [
    "### Check GPU Availability\n",
    "\n",
    "Training is **much faster** on GPU. If CUDA is available, we'll use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed089478",
   "metadata": {},
   "source": [
    "### Train / Fine Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02bc74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbb008",
   "metadata": {},
   "source": [
    "Load BERT with a **classification head** (a new linear layer on top). The `num_labels=2` creates a binary classifier.\n",
    "\n",
    "âš ï¸ You'll see a warning about random weights - this is expected! The classification head is randomly initialized and will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcafab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a82197",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics\n",
    "\n",
    "We compute both **accuracy** and **F1 score**. F1 is especially useful for imbalanced datasets as it considers both precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e3f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4bf56",
   "metadata": {},
   "source": [
    "### Configure Training\n",
    "\n",
    "Key parameters:\n",
    "- **output_dir**: Where to save checkpoints\n",
    "- **eval_strategy**: Evaluate after each epoch\n",
    "- **per_device_train_batch_size**: Samples per batch (reduce if OOM)\n",
    "- **num_train_epochs**: Training iterations over full dataset\n",
    "- **weight_decay**: L2 regularization to prevent overfitting\n",
    "- **load_best_model_at_end**: Keep the best checkpoint based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45432e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e95700",
   "metadata": {},
   "source": [
    "### Create the Trainer\n",
    "\n",
    "The Trainer brings everything together: model, training arguments, datasets, data collator, and metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79d777bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 19:41:32 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/02 19:41:32 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/01/02 19:41:32 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/02 19:41:33 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 02:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356082</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.903678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.396245</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.903879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.520720</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.895369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.33454308717147163, metrics={'train_runtime': 122.8349, 'train_samples_per_second': 89.584, 'train_steps_per_second': 5.617, 'total_flos': 428577075854640.0, 'train_loss': 0.33454308717147163, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may get an error if mlflow or dagshub are installed. To remove that error, you can uninstall \n",
    "# mlflow and dagshub and then restart the kernel\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec0d01",
   "metadata": {},
   "source": [
    "### ðŸš€ Start Training!\n",
    "\n",
    "This will take several minutes. You'll see:\n",
    "- Loss decreasing over time\n",
    "- Accuracy/F1 improving each epoch\n",
    "- Checkpoints being saved\n",
    "\n",
    "**Note**: If you get MLflow errors, uninstall `mlflow` and `dagshub`, then restart the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6f344",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888f92ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4148944914340973,\n",
       " 'eval_accuracy': 0.8226086956521739,\n",
       " 'eval_f1': 0.8702290076335878,\n",
       " 'eval_runtime': 4.8794,\n",
       " 'eval_samples_per_second': 353.525,\n",
       " 'eval_steps_per_second': 22.134,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a906922",
   "metadata": {},
   "source": [
    "Evaluate on the held-out test set to see how well the model generalizes to unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d648e7",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbc6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on new sentences\n",
    "def predict(sentences):\n",
    "    inputs = tokenizer(sentences[\"sentence1\"], sentences[\"sentence2\"], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    return predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d701d",
   "metadata": {},
   "source": [
    "Create a prediction function that:\n",
    "1. Tokenizes input sentence pairs\n",
    "2. Passes through the model\n",
    "3. Returns the predicted class (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70fcec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0]\n"
     ]
    }
   ],
   "source": [
    "sample_sentences = {\n",
    "    \"sentence1\": [\n",
    "        \"PCCW 's chief operating officer , Mike Butcher , and Alex Arena , the chief financial officer , will report directly to Mr So\",\n",
    "        \"The Nasdaq composite index increased 10.73 , or 0.7 percent , to 1,514.77\"\n",
    "    ],\n",
    "    \"sentence2\": [\n",
    "        \"Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So\", \n",
    "        \"The Nasdaq Composite index, full of technology stocks, was lately up around 18 points\"\n",
    "    ]\n",
    "}\n",
    "predictions = predict(sample_sentences)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51636f1",
   "metadata": {},
   "source": [
    "### Test on New Examples\n",
    "\n",
    "Let's test with two sentence pairs:\n",
    "1. Similar sentences about executives reporting structure â†’ should be **1** (paraphrase)\n",
    "2. Different Nasdaq statistics â†’ should be **0** (not paraphrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
