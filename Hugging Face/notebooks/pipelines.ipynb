{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e83c05",
   "metadata": {},
   "source": [
    "# Hugging Face Pipelines üöÄ\n",
    "\n",
    "Pipelines are the **easiest way** to use pretrained models for inference. They handle all the complexity of tokenization, model inference, and post-processing in a single line of code!\n",
    "\n",
    "## What You'll Learn:\n",
    "- Sentiment Analysis\n",
    "- Custom model specification\n",
    "- Language Translation\n",
    "- Zero-Shot Classification\n",
    "- Text Generation\n",
    "- Named Entity Recognition (NER)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c618e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:22.628032084Z",
     "start_time": "2026-01-02T13:35:18.354218881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 19:07:54.828598: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 19:07:54.865891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-02 19:07:56.831482: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 19:07:56.831806: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/btwitsvoid/python/lib64/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2027fb9",
   "metadata": {},
   "source": [
    "### Import the Pipeline\n",
    "\n",
    "The `pipeline` function is the main entry point for all Hugging Face inference tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc06660",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis üòäüò†\n",
    "\n",
    "Classify text as **POSITIVE** or **NEGATIVE**. This is one of the most common NLP tasks, used for:\n",
    "- Customer review analysis\n",
    "- Social media monitoring\n",
    "- Brand sentiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5341e9f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:23.892604831Z",
     "start_time": "2026-01-02T13:35:22.628762124Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "cls = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fc7cc",
   "metadata": {},
   "source": [
    "Create a sentiment classifier. By default, it uses `distilbert-base-uncased-finetuned-sst-2-english`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a50bfd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:24.068250397Z",
     "start_time": "2026-01-02T13:35:23.939285912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9987161159515381}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls(\"Pushpa 2 movie is full of violence and gave me a headache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042a53d",
   "metadata": {},
   "source": [
    "Let's test with a **negative** sentiment example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b98fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:24.126895659Z",
     "start_time": "2026-01-02T13:35:24.069667912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9983184337615967}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls(\"12th fail is such an inspiring movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955ce82",
   "metadata": {},
   "source": [
    "Now a **positive** sentiment example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eaeac7",
   "metadata": {},
   "source": [
    "### Specify a Custom Model üéØ\n",
    "\n",
    "You can use any model from the [Hugging Face Hub](https://huggingface.co/models) by passing the model name. Here we use RoBERTa trained on MNLI for natural language inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fbebc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:25.548660609Z",
     "start_time": "2026-01-02T13:35:24.128510835Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEUTRAL', 'score': 0.7313140630722046}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(model=\"FacebookAI/roberta-large-mnli\")\n",
    "pipe(\"This restaurant is awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46e11c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Language Translation üåç\n",
    "\n",
    "Translate text between languages using neural machine translation models. Helsinki-NLP provides high-quality models for many language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66da1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:28.170625474Z",
     "start_time": "2026-01-02T13:35:25.595388749Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?'}]\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "\n",
    "translation = translator(\"How are you?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63564a2c",
   "metadata": {},
   "source": [
    "Translate English to Hindi using the `Helsinki-NLP/opus-mt-en-hi` model:\n",
    "\n",
    "**Model naming convention**: `opus-mt-{source}-{target}` (e.g., `en-hi` = English ‚Üí Hindi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c4d3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Zero-Shot Classification üéØ\n",
    "\n",
    "Classify text into **custom categories without any training**! The model uses natural language understanding to match text to your provided labels.\n",
    "\n",
    "This is incredibly powerful because:\n",
    "- No training data needed\n",
    "- Change labels anytime\n",
    "- Works for any classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86ae8fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:29.430540906Z",
     "start_time": "2026-01-02T13:35:28.216454205Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I bought the product but it is faulty, I would like to return it and get my money back',\n",
       " 'labels': ['refund', 'existing order', 'new order'],\n",
       " 'scores': [0.812207043170929, 0.17987744510173798, 0.007915535010397434]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"I bought the product but it is faulty, I would like to return it and get my money back\",\n",
    "    candidate_labels=[\"refund\", \"new order\", \"existing order\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094c8b4",
   "metadata": {},
   "source": [
    "Classify a customer support message into categories. The model returns scores for each label:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd802075",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Text Generation ‚úçÔ∏è\n",
    "\n",
    "Generate text continuations from a prompt. Uses autoregressive language models (like GPT-2) that predict the next word given previous context.\n",
    "\n",
    "**Use cases**: Creative writing, code completion, chatbots, content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2a139e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:35:31.550631842Z",
     "start_time": "2026-01-02T13:35:29.477512236Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"To become happy in life, we need to focus on healthy diet and \\xa0prevent disease. This is why I was really surprised that the researchers had failed to find any significant differences in symptoms between men and women for the four nutrients identified as essential for the prevention of cancer.\\nWhat the study said\\nSo what if you're a woman in a situation where you have cancer and you have a lot of other things going on that you are not being able to control? What if you're also a woman in a situation where you have diabetes? What if you're also a woman in a situation where you have a lot of other things going on that you are not being able to control? I think the results of the study were interesting.\\nThe researchers identified the essential nutrients and they found that women in the study had a smaller risk of developing a type of breast cancer. So it's possible that there are other things that are keeping women from being able to control.\\nThere are other factors that also help prevent cancer. There are other medications we can take. And there are other things we can do in the same way, for example, we can use supplements. But I think we need to keep in mind that there's a lot of other things we can do that are helping us prevent cancer and that are helping us prevent diabetes and other types\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"To become happy in life, we need to focus on healthy diet and \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e8bff",
   "metadata": {},
   "source": [
    "The model will complete the sentence. Each run may produce different results due to sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50cd039",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Named Entity Recognition (NER) üè∑Ô∏è\n",
    "\n",
    "Extract and classify entities from text:\n",
    "- **PER**: Person names\n",
    "- **ORG**: Organizations\n",
    "- **LOC**: Locations\n",
    "- **MISC**: Miscellaneous entities\n",
    "\n",
    "**Use cases**: Information extraction, knowledge graphs, document indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77cc43",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-02T13:35:38.516217259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e11439ccb5e4b4fbaf286758823e064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5621f7511d834472a18e086c2857e780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d403cf1c396643de8a47e70ea85cf1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/btwitsvoid/python/lib64/python3.12/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9931652),\n",
       "  'word': 'Mitudru Dutta',\n",
       "  'start': 5,\n",
       "  'end': 18},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': np.float32(0.5309676),\n",
       "  'word': 'Face',\n",
       "  'start': 55,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\")\n",
    "ner(\"I am Mitudru Dutta, and I am currently running Hugging Face models\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659cd71",
   "metadata": {},
   "source": [
    "`aggregation_strategy=\"simple\"` combines multi-token entities (e.g., \"Mitudru Dutta\" as one entity instead of two):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7547a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "| Pipeline | Task | Example Use Case |\n",
    "|----------|------|------------------|\n",
    "| `sentiment-analysis` | Classify positive/negative | Review analysis |\n",
    "| `translation` | Translate between languages | Localization |\n",
    "| `zero-shot-classification` | Classify without training | Ticket routing |\n",
    "| `text-generation` | Generate text | Content creation |\n",
    "| `ner` | Extract entities | Information extraction |\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **One line of code** - Pipelines handle tokenization, inference, and post-processing\n",
    "2. **Customizable** - Use any model from Hugging Face Hub\n",
    "3. **No training required** - Pretrained models work out of the box\n",
    "4. **Zero-shot capable** - Classify into any categories without training data\n",
    "\n",
    "üìñ **Learn more**: [Hugging Face Pipelines Documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
